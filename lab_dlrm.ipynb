{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebf61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.userid = torch.tensor(df[\"userid\"].values, dtype=torch.long)\n",
    "        self.movieid = torch.tensor(df[\"movieid\"].values, dtype=torch.long)\n",
    "        self.gender = torch.tensor(df[\"gender\"].values, dtype=torch.float32)\n",
    "        self.rating_binary = torch.tensor(\n",
    "            df[\"rating_binary\"].values, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        self.genre_lists = df[\"genre_list\"].values\n",
    "        self.max_genres = max(len(g) for g in self.genre_lists)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.userid)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        genres = self.genre_lists[idx]\n",
    "        genre_tensor = torch.zeros(self.max_genres, dtype=torch.long)\n",
    "        genre_tensor[: len(genres)] = torch.tensor(genres, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"userid\": self.userid[idx],\n",
    "            \"movieid\": self.movieid[idx],\n",
    "            \"gender\": self.gender[idx],\n",
    "            \"genres\": genre_tensor,\n",
    "            \"genre_length\": len(genres),\n",
    "            \"label\": self.rating_binary[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b0f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrec.sparse.jagged_tensor import KeyedJaggedTensor\n",
    "\n",
    "\n",
    "def collate_fn(batch: list[dict]):\n",
    "    batch_size = len(batch)\n",
    "    userid = torch.stack([b[\"userid\"] for b in batch])\n",
    "    movieid = torch.stack([b[\"movieid\"] for b in batch])\n",
    "\n",
    "    genre_values = []\n",
    "    genre_lengths = []\n",
    "    for b in batch:\n",
    "        length = b[\"genre_length\"]\n",
    "        genre_values.extend(b[\"genres\"][:length].tolist())\n",
    "        genre_lengths.append(length)\n",
    "\n",
    "    sparse_features = KeyedJaggedTensor(\n",
    "        keys=[\"userid\", \"movieid\", \"genres\"],\n",
    "        values=torch.cat(\n",
    "            [userid, movieid, torch.tensor(genre_values, dtype=torch.long)]\n",
    "        ),\n",
    "        lengths=torch.tensor([1] * batch_size + [1] * batch_size + genre_lengths),\n",
    "    )\n",
    "\n",
    "    dense_features = torch.stack([b[\"gender\"] for b in batch]).unsqueeze(1)\n",
    "    labels = torch.stack([b[\"label\"] for b in batch])\n",
    "    return sparse_features, dense_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46085faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchrec.models.dlrm import DLRM\n",
    "from torchrec.modules.embedding_configs import EmbeddingBagConfig\n",
    "from torchrec.modules.embedding_modules import EmbeddingBagCollection\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "class DLRMRecommender:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_movies: int,\n",
    "        num_genres: int,\n",
    "        embedding_dim: int = 64,\n",
    "        dense_arch_layer_sizes: list[int] = [128, 64],\n",
    "        over_arch_layer_sizes: list[int] = [128, 64, 1],\n",
    "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    ):\n",
    "        self.device = device\n",
    "\n",
    "        eb_configs = [\n",
    "            EmbeddingBagConfig(\n",
    "                name=\"userid\",\n",
    "                embedding_dim=embedding_dim,\n",
    "                num_embeddings=num_users,\n",
    "                feature_names=[\"userid\"],\n",
    "            ),\n",
    "            EmbeddingBagConfig(\n",
    "                name=\"movieid\",\n",
    "                embedding_dim=embedding_dim,\n",
    "                num_embeddings=num_movies,\n",
    "                feature_names=[\"movieid\"],\n",
    "            ),\n",
    "            EmbeddingBagConfig(\n",
    "                name=\"genres\",\n",
    "                embedding_dim=embedding_dim,\n",
    "                num_embeddings=num_genres,\n",
    "                feature_names=[\"genres\"],\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        embedding_bag_collection = EmbeddingBagCollection(\n",
    "            tables=eb_configs,\n",
    "            device=torch.device(device),\n",
    "        )\n",
    "\n",
    "        self.model = DLRM(\n",
    "            embedding_bag_collection=embedding_bag_collection,\n",
    "            dense_in_features=1,\n",
    "            dense_arch_layer_sizes=dense_arch_layer_sizes,\n",
    "            over_arch_layer_sizes=over_arch_layer_sizes,\n",
    "            dense_device=device,\n",
    "        ).to(device)\n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def train_epoch(self, train_loader: DataLoader) -> float:\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for sparse_features, dense_features, labels in tqdm(train_loader, total=len(train_loader)):\n",
    "            sparse_features = sparse_features.to(self.device)\n",
    "            dense_features = dense_features.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            logits = self.model(dense_features, sparse_features)\n",
    "            loss = self.criterion(logits.squeeze(), labels)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        return total_loss / num_batches\n",
    "\n",
    "    def evaluate(self, val_loader: DataLoader) -> dict[str, float]:\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for sparse_features, dense_features, labels in val_loader:\n",
    "                sparse_features = sparse_features.to(self.device)\n",
    "                dense_features = dense_features.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                logits = self.model(dense_features, sparse_features)\n",
    "                loss = self.criterion(logits.squeeze(), labels)\n",
    "\n",
    "                preds = torch.sigmoid(logits.squeeze())\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "        acc = accuracy_score(all_labels, (all_preds > 0.5).astype(int))\n",
    "\n",
    "        return {\"loss\": total_loss / num_batches, \"auc\": auc, \"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfe3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_recommendation_system(\n",
    "    parquet_path: str,\n",
    "    num_epochs: int = 20,\n",
    "    batch_size: int = 512,\n",
    "    embedding_dim: int = 64,\n",
    "    val_split: float = 0.2,\n",
    "):\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "\n",
    "    num_users = df[\"userid\"].max() + 1\n",
    "    num_movies = df[\"movieid\"].max() + 1\n",
    "\n",
    "    all_genres = [g for genre_list in df[\"genre_list\"] for g in genre_list]\n",
    "    num_genres = max(all_genres) + 1\n",
    "\n",
    "    print(f\"Dataset stats:\")\n",
    "    print(f\"  Users: {num_users}\")\n",
    "    print(f\"  Movies: {num_movies}\")\n",
    "    print(f\"  Genres: {num_genres}\")\n",
    "    print(f\"  Samples: {len(df)}\")\n",
    "\n",
    "    train_df, val_df = train_test_split(df, test_size=val_split, random_state=42)\n",
    "\n",
    "    train_dataset = MovieLensDataset(train_df)\n",
    "    val_dataset = MovieLensDataset(val_df)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    recommender = DLRMRecommender(\n",
    "        num_users=num_users,\n",
    "        num_movies=num_movies,\n",
    "        num_genres=num_genres,\n",
    "        embedding_dim=embedding_dim,\n",
    "        dense_arch_layer_sizes=[256, 128],\n",
    "        over_arch_layer_sizes=[256, 128, 64, 1],\n",
    "    )\n",
    "\n",
    "    best_auc = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = recommender.train_epoch(train_loader)\n",
    "        val_metrics = recommender.evaluate(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(f\"  Val AUC: {val_metrics['auc']:.4f}\")\n",
    "        print(f\"  Val Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "\n",
    "        if val_metrics[\"auc\"] > best_auc:\n",
    "            best_auc = val_metrics[\"auc\"]\n",
    "            torch.save(recommender.model.state_dict(), \"best_dlrm_model.pt\")\n",
    "            print(f\"  ✓ New best model saved! (AUC: {best_auc:.4f})\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f\"Training complete! Best validation AUC: {best_auc:.4f}\")\n",
    "    return recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff52797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset stats:\n",
      "  Users: 6041\n",
      "  Movies: 3953\n",
      "  Genres: 18\n",
      "  Samples: 1000209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/782 [00:00<?, ?it/s]W1209 17:03:33.577000 31544 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1209 17:03:33.577000 31545 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1209 17:03:33.577000 31546 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1209 17:03:33.577000 31547 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1209 17:03:33.633000 31424 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "100%|██████████| 782/782 [00:15<00:00, 50.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  Train Loss: 0.5545\n",
      "  Val Loss: 0.5337\n",
      "  Val AUC: 0.7981\n",
      "  Val Accuracy: 0.7315\n",
      "  ✓ New best model saved! (AUC: 0.7981)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 75.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "  Train Loss: 0.5109\n",
      "  Val Loss: 0.5232\n",
      "  Val AUC: 0.8081\n",
      "  Val Accuracy: 0.7391\n",
      "  ✓ New best model saved! (AUC: 0.8081)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:10<00:00, 73.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "  Train Loss: 0.4677\n",
      "  Val Loss: 0.5238\n",
      "  Val AUC: 0.8112\n",
      "  Val Accuracy: 0.7405\n",
      "  ✓ New best model saved! (AUC: 0.8112)\n",
      "\n",
      "Training complete! Best validation AUC: 0.8112\n"
     ]
    }
   ],
   "source": [
    "recommender = train_recommendation_system(\n",
    "    parquet_path=\"data/preprocessed.parquet\",\n",
    "    num_epochs=3,\n",
    "    batch_size=1024,\n",
    "    embedding_dim=128,\n",
    "    val_split=0.2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

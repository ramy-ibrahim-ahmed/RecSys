{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb64a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_PATH = \"data/preprocessed.parquet\"\n",
    "VAL_SPLIT = 0.2\n",
    "BATCH_SIZE = 2048\n",
    "EMBEDDING_DIM = 128\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfe3fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset stats:\n",
      "  Users: 6041\n",
      "  Movies: 3953\n",
      "  Genres: 18\n",
      "  Samples: 1000209\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_parquet(PARQUET_PATH)\n",
    "\n",
    "num_users = df[\"userid\"].max() + 1\n",
    "num_movies = df[\"movieid\"].max() + 1\n",
    "all_genres = [g for genre_list in df[\"genre_list\"] for g in genre_list]\n",
    "num_genres = max(all_genres) + 1\n",
    "\n",
    "print(f\"Dataset stats:\")\n",
    "print(f\"  Users: {num_users}\")\n",
    "print(f\"  Movies: {num_movies}\")\n",
    "print(f\"  Genres: {num_genres}\")\n",
    "print(f\"  Samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ada196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:54: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  ALLREDUCE = partial(_ddp_comm_hook_wrapper, comm_hook=default.allreduce_hook)\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:55: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  FP16_COMPRESS = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:58: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  BF16_COMPRESS = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:61: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  QUANTIZE_PER_TENSOR = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:64: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  QUANTIZE_PER_CHANNEL = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:67: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  POWER_SGD = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:74: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  POWER_SGD_RANK2 = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:80: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  BATCHED_POWER_SGD = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:85: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  BATCHED_POWER_SGD_RANK2 = partial(\n",
      "/home/ramy/code/recsys/.venv/lib/python3.13/site-packages/torch/distributed/algorithms/ddp_comm_hooks/__init__.py:90: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  NOOP = partial(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.collator import collate_fn\n",
    "from utils.dataset import MovieLensDataset\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=VAL_SPLIT, random_state=42)\n",
    "train_dataset = MovieLensDataset(train_df)\n",
    "val_dataset = MovieLensDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08070f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/391 [00:00<?, ?it/s]W1211 15:43:39.290000 30166 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1211 15:43:39.290000 30170 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1211 15:43:39.290000 30173 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1211 15:43:39.290000 30174 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "W1211 15:43:39.379000 29997 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n",
      "100%|██████████| 391/391 [00:29<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  Train Loss: 0.5632\n",
      "  Val Loss: 0.5364\n",
      "  Val AUC: 0.7958\n",
      "  Val Accuracy: 0.7295\n",
      "  ✓ New best model saved! (AUC: 0.7958)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:09<00:00, 42.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "  Train Loss: 0.5133\n",
      "  Val Loss: 0.5309\n",
      "  Val AUC: 0.8025\n",
      "  Val Accuracy: 0.7343\n",
      "  ✓ New best model saved! (AUC: 0.8025)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 53.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "  Train Loss: 0.4791\n",
      "  Val Loss: 0.5317\n",
      "  Val AUC: 0.8087\n",
      "  Val Accuracy: 0.7378\n",
      "  ✓ New best model saved! (AUC: 0.8087)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 55.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "  Train Loss: 0.4348\n",
      "  Val Loss: 0.5468\n",
      "  Val AUC: 0.8034\n",
      "  Val Accuracy: 0.7317\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 51.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "  Train Loss: 0.3705\n",
      "  Val Loss: 0.6081\n",
      "  Val AUC: 0.7915\n",
      "  Val Accuracy: 0.7223\n",
      "\n",
      "Training complete! Best validation AUC: 0.8087\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from arch.dlrm import DLRMRecommender\n",
    "\n",
    "dlrm_model = DLRMRecommender(\n",
    "    num_users=num_users,\n",
    "    num_movies=num_movies,\n",
    "    num_genres=num_genres,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    dense_arch_layer_sizes=[256, 128],\n",
    "    over_arch_layer_sizes=[256, 128, 64, 1],\n",
    ")\n",
    "\n",
    "best_auc = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = dlrm_model.train_epoch(train_loader)\n",
    "    val_metrics = dlrm_model.evaluate(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Val AUC: {val_metrics['auc']:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "\n",
    "    if val_metrics[\"auc\"] > best_auc:\n",
    "        best_auc = val_metrics[\"auc\"]\n",
    "        torch.save(dlrm_model.model.state_dict(), \"best_dlrm_model.pt\")\n",
    "        print(f\"  ✓ New best model saved! (AUC: {best_auc:.4f})\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"Training complete! Best validation AUC: {best_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
